  
# üß† NLP Lab Manual: 15 Experiments

A complete **Natural Language Processing (NLP)** lab manual containing **15 hands-on experiments** to understand and implement various NLP tasks using **Python**, **NLTK**, and **spaCy**.

Each experiment is designed to be **student-friendly**, with **clear explanations**, **minimal code**, and **visualizations where applicable**.

---

## üìö Table of Contents

1. [About the Manual](#about-the-manual)
2. [Requirements & Installation](#requirements--installation)
3. [How to Run the Labs](#how-to-run-the-labs)
4. [List of Experiments](#list-of-experiments)
5. [Optional Enhancements](#optional-enhancements)
6. [License](#license)

---

## üßæ About the Manual

This manual includes 15 lab experiments covering core **NLP preprocessing techniques**, **text analysis**, **syntactic parsing**, **TF-IDF**, **POS tagging**, **chunking**, **spell checking**, and more.

Each lab includes:
- ‚úÖ Clear objective
- ‚úÖ Step-by-step implementation
- ‚úÖ Visualizations (where applicable)
- ‚úÖ Notes for students
- ‚úÖ Sample output

Ideal for **students**, **teachers**, and **beginners in NLP**.

---

## üì¶ Requirements & Installation

### üêç Python Version
- Python 3.7 or higher

### üì¶ Libraries Used
- `nltk`
- `spacy`
- `matplotlib`
- `seaborn` (for visualization)
- `pandas`
- `scikit-learn` (for TF-IDF)
- `textblob` (for spell checking)
- `re` and `collections` (built-in)

### üîß Installation Steps

1. **Install Python** (if not already installed)

2. **Install Required Libraries**:

```bash
pip install nltk spacy matplotlib seaborn pandas scikit-learn textblob
```

3. **Download spaCy English Model**:

```bash
python -m spacy download en_core_web_sm
```

4. **Download NLTK Corpora**:

```python
python -c "import nltk; nltk.download(['punkt', 'stopwords', 'wordnet', 'averaged_perceptron_tagger', 'brown', 'gutenberg', 'names', 'maxent_ne_chunker', 'words'])"
```

5. **Install TextBlob Corpora**:

```bash
python -m textblob.download_corpora
```

---

## üèÉ‚Äç‚ôÇÔ∏è How to Run the Labs

1. Clone or download the repository:
```bash
https://github.com/GadiyamulaHarshavardhan/NLP_Manual.git
```

2. Navigate to the experiment folder:
```bash
cd nlp-lab-manual/Experiment-1
```

3. Run the script:
```bash
python experiment1.py
```

Replace `experiment1.py` with the actual script name.

---

## üß™ List of Experiments

| Lab No. | Title | Description |
|--------|-------|-------------|
| **Lab 1** | Installation & Exploring NLP Tools | Install NLTK, spaCy, WordCloud, and download corpora |
| **Lab 2(i)** | Tokenization | Word, sentence, and paragraph tokenization |
| **Lab 2(ii)** | Word Count | Count total and distinct words in a corpus |
| **Lab 3(i)** | N-grams | Generate uni-grams, bi-grams, tri-grams, and n-grams |
| **Lab 3(ii)** | Word Probability | Calculate P(w2 | w1) using bi-grams |
| **Lab 4(i)** | Collocations | Identify word associations using NLTK |
| **Lab 4(ii)** | Prefix Search | Find words starting with a given prefix |
| **Lab 4(iii)** | Long Words | Print words longer than 4 characters |
| **Lab 5(i)** | Math Expressions | Identify mathematical expressions using regex |
| **Lab 5(ii)** | Email Components | Extract parts of an email address |
| **Lab 6(i)** | Synonyms & Antonyms | Use WordNet to find word relationships |
| **Lab 6(ii)** | Hyponymy & Polysemy | Explore semantic relationships |
| **Lab 7(i)** | Stopwords | Identify stop words in a given text |
| **Lab 7(ii)** | Top Frequent Words | Find top 50 non-stop words |
| **Lab 8** | Stemming | Compare Porter, Snowball, Lancaster, and Regexp stemmers |
| **Lab 9** | Lemmatization | Compare NLTK and spaCy lemmatization |
| **Lab 10(i)** | Conditional Frequency | Use CFD for corpus analysis |
| **Lab 10(ii)** | Four-letter Words | Frequency distribution of 4-letter words |
| **Lab 10(iii)** | Tag Frequency | Most frequent POS tags in Brown Corpus |
| **Lab 10(iv)** | Preceding Tags | Tags that commonly precede nouns |
| **Lab 11(i)** | POS Tagging | Tag words using NLTK and spaCy |
| **Lab 11(ii)** | Word Ambiguity | Find word with most distinct tags |
| **Lab 11(iii)** | Tag Frequency | List tags in decreasing order |
| **Lab 11(iv)** | Tags Before Nouns | Find tags preceding noun phrases |
| **Lab 12** | TF-IDF Vectorization | Implement TF-IDF on a corpus |
| **Lab 13** | Chunking & Chinking | Group and filter phrases |
| **Lab 14(i)** | Misspelled Words | Detect spelling errors |
| **Lab 14(ii)** | Misspelled Frequency | Table of misspelled word frequencies |
| **Lab 15** | NLP Preprocessing | Complete pipeline for NLP tasks |

---

## üõ†Ô∏è Optional Enhancements

Each lab includes optional enhancements like:
- Visualization using **matplotlib/seaborn**
- Working with real **corpora** (`gutenberg`, `brown`, `reuters`)
- Saving output to **CSV/JSON**
- Building **GUI interfaces**
- Exporting **frequency tables**
- Integrating with **machine learning pipelines**

---

## üìÑ License

This project is licensed under the **MIT License** ‚Äì see the [LICENSE](LICENSE) file for details.

---

## üì¨ Contact

If you have any questions, suggestions, or want to contribute, feel free to reach out:

üìß **Email**: vamsi.darion@gmail.com  
üêô **GitHub**: [github.com/vamsidarion](https://github.com/vamsidarion)

---

## üôå Thank You!

This lab manual is designed to help students understand **core NLP concepts** with **hands-on practice**. Happy coding! üßë‚Äçüíª

---


